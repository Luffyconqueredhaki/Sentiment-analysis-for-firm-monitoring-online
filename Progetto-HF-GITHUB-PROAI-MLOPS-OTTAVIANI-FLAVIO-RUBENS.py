# -*- coding: utf-8 -*-
"""Progetto-HF-GITHUB-PROAI-MLOPS-OTTAVIANI-FLAVIO-RUBENS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WLs3Qcnhxh5jc_vzCruTr2OBOmE1rANK

Progetto MLOps: Sentiment Analysis for Firm Monitoring Online
Autore: Flavio Rubens Ottaviani
Repository: https://github.com/Luffyconqueredhaki/Sentiment-analysis-for-firm-monitoring-online
Modello: cardiffnlp/twitter-roberta-base-sentiment-latest
"""

# Installazione dipendenze
!pip install -q transformers scipy matplotlib pandas huggingface-hub

# Import librerie
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, pipeline
from scipy.special import softmax
import torch

# Funzione per preprocessare il testo
def preprocess(text):
    new_text = []
    for t in text.split(" "):
        t = '@user' if t.startswith('@') and len(t) > 1 else t
        t = 'http' if t.startswith('http') else t
        new_text.append(t)
    return " ".join(new_text)

# Caricamento del modello pre-addestrato
MODEL = "cardiffnlp/twitter-roberta-base-sentiment-latest"

tokenizer = AutoTokenizer.from_pretrained(MODEL, token=False)
config = AutoConfig.from_pretrained(MODEL, token=False)
model = AutoModelForSequenceClassification.from_pretrained(MODEL, token=False)

# Creo la pipeline per l'analisi del sentiment
sentiment_pipeline = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# Verifico disponibilita GPU
if torch.cuda.is_available():
    print("GPU disponibile")

# Test su testi di esempio
test_texts = [
    "I hate work with powerpoint!",
    "My car with electronics tuning get 30 HP, is very great to drive, now!",
    "Gullo is a great king",
    "Tomorrow will be great weather"
]

print("Test analisi sentiment:")
for text in test_texts:
    text_clean = preprocess(text)
    result = sentiment_pipeline(text_clean)
    print(f"Testo: {text}")
    print(f"Risultato: {result}\n")

# Dataset aziendale MachineInnovators Inc.
company_data = {
    "tweet": [
        "MachineInnovators Inc. is the best company ever!",
        "I'm not happy with MachineInnovators service.",
        "Neutral statement about MachineInnovators Inc.",
        "Amazing product launch by MachineInnovators Inc.",
        "This is the worst experience with MachineInnovators.",
        "I think MachineInnovators Inc. is doing fine."
    ]
}

df = pd.DataFrame(company_data)

# Analisi sentiment per ogni tweet
sentiments = []
for tweet in df['tweet']:
    tweet_clean = preprocess(tweet)
    result = sentiment_pipeline(tweet_clean)[0]
    sentiments.append(result['label'])

df['sentiment'] = sentiments

# Visualizzo i risultati
print("Risultati analisi aziendale:")
print(df)

# Calcolo la distribuzione dei sentiment
sentiment_counts = df['sentiment'].value_counts()

# Creo il grafico
plt.figure(figsize=(8, 6))
plt.bar(sentiment_counts.index, sentiment_counts.values, color=['red', 'gray', 'green'])
plt.title('Distribuzione Sentiment per MachineInnovators Inc.')
plt.xlabel('Sentiment')
plt.ylabel('Conteggio')
plt.grid(axis='y', alpha=0.3)
plt.show()

# Salvo il modello localmente
model.save_pretrained("./model")
tokenizer.save_pretrained("./model")
print("Modello salvato in ./model")

# Upload su Hugging Face Hub
from huggingface_hub import notebook_login, HfApi

notebook_login()

api = HfApi()
REPO_ID = "INSERIRE REPOURL"

api.upload_folder(
    folder_path="./model",
    path_in_repo=".",
    repo_id=REPO_ID,
    repo_type="model",
    commit_message="Deploy modello sentiment per firm monitoring"
)

print(f"Modello caricato su: https://huggingface.co/{REPO_ID}")

